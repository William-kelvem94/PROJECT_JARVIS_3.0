@echo off
echo ğŸš€ Configurando JARVIS 3.0 com IA Local Ollama
echo ==============================================

REM Parar containers existentes
echo ğŸ“¦ Parando containers existentes...
docker stop Ollama_IA_LOCAL Jarvis_WebUI Jarvis_Training 2>nul

REM Iniciar nova stack completa
echo ğŸ—ï¸ Iniciando stack completa...
docker-compose up -d

REM Aguardar Ollama ficar pronto
echo â³ Aguardando Ollama inicializar...
timeout /t 10 /nobreak >nul

REM Verificar se modelos estÃ£o disponÃ­veis
echo ğŸ§  Verificando modelos...
docker exec Ollama_IA_LOCAL ollama list

REM Criar modelo personalizado Jarvis
echo ğŸ¯ Criando modelo personalizado do Jarvis...
docker exec Ollama_IA_LOCAL ollama create jarvis-personal -f /training_data/Modelfile

REM Testar modelo personalizado
echo ğŸ§ª Testando modelo personalizado...
docker exec Ollama_IA_LOCAL ollama run jarvis-personal "OlÃ¡, eu sou o Will. Como vocÃª estÃ¡?"

echo.
echo âœ… CONFIGURAÃ‡ÃƒO CONCLUÃDA!
echo =========================
echo.
echo ğŸŒ Acessos disponÃ­veis:
echo    â€¢ WebUI (ChatGPT-like): http://localhost:3000
echo    â€¢ Jupyter (Treinamento): http://localhost:8888 (token: jarvis2025)
echo    â€¢ Ollama API: http://localhost:11434
echo.
echo ğŸ¤– Para testar seu Jarvis personalizado:
echo    docker exec -it Ollama_IA_LOCAL ollama run jarvis-personal
echo.
echo ğŸ”§ Comandos Ãºteis:
echo    â€¢ Ver logs: docker-compose logs -f
echo    â€¢ Parar tudo: docker-compose down
echo    â€¢ Chat direto: docker exec -it Ollama_IA_LOCAL ollama run jarvis-personal
echo.
echo ğŸ‰ Seu Jarvis estÃ¡ pronto para usar!
pause
